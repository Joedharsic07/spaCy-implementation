{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjtYqKD7fdrHwVs+B4LKI5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52T-eW8bMjN-"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part-of-speech tagging"
      ],
      "metadata": {
        "id": "3v8Qh1bYM8bG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "for token in doc:\n",
        "    print(token.text,token.lemma_,token.pos_,token.tag_,token.dep_,token.shape,token.is_alpha,token.is_stop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXN6s3crMneW",
        "outputId": "8b0dcd66-2a4a-476f-8293-2b0705128718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple Apple PROPN NNP nsubj 16072095006890171862 True False\n",
            "is be AUX VBZ aux 4370460163704169311 True True\n",
            "looking look VERB VBG ROOT 13110060611322374290 True False\n",
            "at at ADP IN prep 4370460163704169311 True True\n",
            "buying buy VERB VBG pcomp 13110060611322374290 True False\n",
            "U.K. U.K. PROPN NNP dobj 9346084826459880894 False False\n",
            "startup startup NOUN NN dep 13110060611322374290 True False\n",
            "for for ADP IN prep 4088098365541558500 True True\n",
            "$ $ SYM $ quantmod 11283501755624150392 False False\n",
            "1 1 NUM CD compound 8148669997605808657 False False\n",
            "billion billion NUM CD pobj 13110060611322374290 True False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Morphology\n"
      ],
      "metadata": {
        "id": "tVThxzcZNz3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "npl=spacy.load(\"en_core_web_sm\")\n",
        "print(\"pipeline:\",nlp.pipe_names)\n",
        "doc=npl(\"I was reading the paper\")\n",
        "token=doc[0]\n",
        "print(token.morph)\n",
        "print(token.morph.get(\"ProneType\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFc6KOyzNpV9",
        "outputId": "5fbb0ba8-7dc2-424d-e5e4-41b2f0a5ce0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pipeline: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
            "Case=Nom|Number=Sing|Person=1|PronType=Prs\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Statistical morphology"
      ],
      "metadata": {
        "id": "zPDENlLVOplq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhLLEoEjURxE",
        "outputId": "ff2b3977-81d6-43c8-adc9-f9223b53ed51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.10.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"de_core_news_sm\")\n",
        "doc = nlp(\"Wo bist du?\")\n",
        "print(doc[2].morph)\n",
        "print(doc[2].pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBctwwHAOhHM",
        "outputId": "9ef40a04-8382-4bc4-a291-003ca4d429e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Case=Nom|Number=Sing|Person=2|PronType=Prs\n",
            "PRON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rule-based morphology"
      ],
      "metadata": {
        "id": "elASEmJeUv6y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uQtjCKUWU-lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"where are you?\")\n",
        "print(doc[2].morph)\n",
        "print(doc[2].pos_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJMU4CYaUu5c",
        "outputId": "702c2e76-8b32-4eaa-da5e-33ff5ca0484a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Case=Nom|Person=2|PronType=Prs\n",
            "PRON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lemmatization"
      ],
      "metadata": {
        "id": "-9emSpE8VwCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "lemmatizer=nlp.get_pipe(\"lemmatizer\")\n",
        "print(lemmatizer.mode)\n",
        "doc=nlp(\"I was reading the paper\")\n",
        "print([token.lemma_ for token in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66j_09QuUkfG",
        "outputId": "94afeae1-39f6-4deb-996a-46744f4365d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rule\n",
            "['I', 'be', 'read', 'the', 'paper']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lookup lemmatizer\n",
        "nlp=spacy.blank(\"sv\") #Create a blank Swedish pipeline\n",
        "nlp.add_pipe(\"lemmatizer\",config={\"mode\":\"lookup\"}) # Add a lemmatizer in \"lookup\" mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csozG3jhV8en",
        "outputId": "813391c0-0237-46e1-fcb8-b7a253766e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.lemmatizer.Lemmatizer at 0x7ced4e0ad100>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rule-based lemmatizer Needs model\n",
        "nlp=spacy.blank(\"de\") # Create a blank German model\n",
        "nlp.add_pipe(\"morphologizer\")# Add morphologizer pipe\n",
        "nlp.add_pipe(\"lemmatizer\",config={\"mode\":\"rule\"}) # Add the lemmatizer in \"rule\" mode\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdL9mfroXSUS",
        "outputId": "b96d1e51-0dc1-4955-f3fa-09f7e470ea02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.lemmatizer.Lemmatizer at 0x7ced4d067d40>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainable lemmatizer\n",
        "nlp=spacy.blank(\"en\")  # Create a blank English model\n",
        "nlp.add_pipe(\"trainable_lemmatizer\",name=\"lemmatizer\") # Add trainable lemmatizer to the pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3e8kTR8ZQWR",
        "outputId": "f590b9a8-6f68-4d30-82d7-5df55bbe3361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.edit_tree_lemmatizer.EditTreeLemmatizer at 0x7ced46b33400>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dependency Parsing Needs model"
      ],
      "metadata": {
        "id": "30CuF_ZCdCZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Noun chunk\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"Autonomes cars shift insurance liability toward manufacturers\")\n",
        "for chunk in doc.noun_chunks:\n",
        "  print(chunk.text,chunk.root.text,chunk.root.dep_,chunk.root.head.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9V5CGnCdBsw",
        "outputId": "18ffc075-e410-44e1-8568-b11a54226a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autonomes cars cars nsubj shift\n",
            "insurance liability liability dobj shift\n",
            "manufacturers manufacturers pobj toward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Navigating the parse tree\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"Autonomes cars shift insurance liability toward manufacturers\")\n",
        "for token in doc:\n",
        "  print(token.text,token.dep_,token.head.text,token.head.pos_,[child for child in token.children])"
      ],
      "metadata": {
        "id": "lXtV0ky9Z0Ew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5f9ae1-b092-4b17-a072-be272dcef143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autonomes compound cars NOUN []\n",
            "cars nsubj shift VERB [Autonomes]\n",
            "shift ROOT shift VERB [cars, liability, toward]\n",
            "insurance compound liability NOUN []\n",
            "liability dobj shift VERB [insurance]\n",
            "toward prep shift VERB [manufacturers]\n",
            "manufacturers pobj toward ADP []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding Verbs with Subjects from above\n",
        "from spacy.symbols import nsubj,VERB\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"Autonomes cars shift insurance liability toward manufacturers\")\n",
        "verbs=set()\n",
        "for possible_subject in doc:\n",
        "  if possible_subject.dep == nsubj and possible_subject.head.pos == VERB:\n",
        "    verbs.add(possible_subject.head)\n",
        "print(verbs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sg2E5_zx4rD",
        "outputId": "97730331-b716-4638-eb7d-ac8af49b55ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{shift}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding a verb with a subject from below\n",
        "verbs=[]\n",
        "for possible_verb in doc:\n",
        "  if possible_verb.pos == VERB:\n",
        "    for possible_subject in possible_verb.children:\n",
        "      if possible_subject.dep == nsubj:\n",
        "        verbs.append(possible_verb)\n",
        "print(verbs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BXTBdYbPOr-",
        "outputId": "743b5501-d827-4e85-cf8b-4041170b93ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[shift]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# itrating around the local tree\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"bright red apples on the tree\")\n",
        "print([token.text for token in doc[2].lefts])\n",
        "print([token.text for token in doc[2].rights])\n",
        "print(doc[2].n_lefts)\n",
        "print(doc[2].n_rights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUt8nIdJSXWr",
        "outputId": "1a0ee2ef-841c-4a37-b7ef-aceab910fe0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bright', 'red']\n",
            "['on']\n",
            "2\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting Left and Right Dependencies in German\n",
        "nlp=spacy.load(\"de_core_news_sm\")\n",
        "doc=nlp(\"schöne rote Äpfel auf dem Baum\")\n",
        "print([token.text for token in doc[2].lefts])\n",
        "print([token.text for token in doc[2].rights])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3c2AOLvUlbs",
        "outputId": "50436e4b-65b8-444e-8bb0-253fbd4b7177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['schöne', 'rote']\n",
            "['auf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging a Span in English Text\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"Credit and mortgage account holders must submit their requests\")\n",
        "span=doc[doc[4].left_edge.i:doc[4].right_edge.i+1]\n",
        "with doc.retokenize() as retokenizer:\n",
        "  retokenizer.merge(span)\n",
        "for token in doc:\n",
        "  print(token.text,token.pos_,token.dep_,token.head.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADBqF0PYVCRG",
        "outputId": "8e44b91e-31cb-4fcb-83e1-dc656afb43b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Credit and mortgage account holders NOUN nsubj submit\n",
            "must AUX aux submit\n",
            "submit VERB ROOT submit\n",
            "their PRON poss requests\n",
            "requests NOUN dobj submit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting MONEY Entities from Multiple Texts\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "nlp.add_pipe(\"merge_entities\")\n",
        "nlp.add_pipe(\"merge_noun_chunks\")\n",
        "doc=nlp(\"Credit and mortgage account holders must submit their requests\")\n",
        "TEXTS=[\n",
        "    \"Net income was $9.4 million compared to the prior year of $2.7 million.\",\n",
        "    \"Revenue exceeded twelve billion dollars, with a loss of $1b.\",\n",
        "]\n",
        "for doc in nlp.pipe(TEXTS):\n",
        "\n",
        "\n",
        "  for token in doc:\n",
        "    if token.ent_type_==\"MONEY\":\n",
        "      if token.dep_ in (\"attr\",\"dobj\"):\n",
        "        subject=[w for w in token.head.lefts if w.dep_==\"nsubj\"]\n",
        "        if subject:\n",
        "          print(subject[0],\"-->\",token)\n",
        "        elif token.dep_==\"pobj\" and token.head.dep_ == \"pep\":\n",
        "          print(token.head.head,\"-->\",token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKjLIINZl3KP",
        "outputId": "d1063fe7-717e-423a-fc5c-9a9b8f766a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net income --> $9.4 million\n",
            "Revenue --> twelve billion dollars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing dependencies"
      ],
      "metadata": {
        "id": "K6jAVvE8AMSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"Autonomous cars shift insurance liability towards manufactures\")\n",
        "displacy.render(doc,style=\"dep\")"
      ],
      "metadata": {
        "id": "xrtoIZhVVRsa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "f2f991c2-575d-421d-d700-b08b2904b71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"6441daed17a442d29b1860707ca830fa-0\" class=\"displacy\" width=\"1275\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Autonomous</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">cars</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">shift</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">insurance</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">liability</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">towards</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">manufactures</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6441daed17a442d29b1860707ca830fa-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6441daed17a442d29b1860707ca830fa-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6441daed17a442d29b1860707ca830fa-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6441daed17a442d29b1860707ca830fa-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6441daed17a442d29b1860707ca830fa-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6441daed17a442d29b1860707ca830fa-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6441daed17a442d29b1860707ca830fa-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6441daed17a442d29b1860707ca830fa-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6441daed17a442d29b1860707ca830fa-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6441daed17a442d29b1860707ca830fa-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6441daed17a442d29b1860707ca830fa-0-5\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6441daed17a442d29b1860707ca830fa-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1095.0,179.0 L1103.0,167.0 1087.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"The lifeless body of Mukesh Chandrakar, a journalist from Maoist hotbed of Bijapur, was discovered from a septic tank on January 3, 2025. The 33-year-old had been missing since January 1 night. Known for his fearless reporting on local issues, including exposing corruption in government contracts, Mukesh's death has sent shockwaves through the region.\")\n",
        "displacy.render(doc,style=\"ent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "FNq5fbgfA4Lz",
        "outputId": "af7c9f95-238a-429e-beb6-1e4b933e6e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The lifeless body of \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mukesh Chandrakar\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", a journalist from \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Maoist\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " hotbed of \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bijapur\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", was discovered from a septic tank on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    January 3, 2025\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". The \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    33-year-old\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " had been missing since \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    January 1 night\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". Known for his fearless reporting on local issues, including exposing corruption in government contracts, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mukesh\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "'s death has sent shockwaves through the region.</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Name entity recognition"
      ],
      "metadata": {
        "id": "_0YSCSp1EnQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Name entity recognition\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "for ent in doc.ents:\n",
        "  print(ent.text,ent.start_char,ent.end_char,ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozE28Kk0DxCB",
        "outputId": "19ebde90-12d2-4a35-a34a-701c03e6f64e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple 0 5 ORG\n",
            "U.K. 27 31 GPE\n",
            "$1 billion 44 54 MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Acessing entity annotations and labels\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"San fransisco considers banning sidewalk delivery robots\")\n",
        "ents=[(e.text,e.start_char,e.end_char,e.label_) for e in doc.ents]\n",
        "print(\"Before\",ents)\n",
        "ent_san=doc[0].text,doc[0].ent_iob,doc[0].ent_type_\n",
        "ent_fran=doc[1].text,doc[1].ent_iob,doc[1].ent_type_\n",
        "print(ent_san)\n",
        "print(ent_fran)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKN3jQErE9ZU",
        "outputId": "ead63332-fc3c-4172-aed6-6b3f94caf3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before [('San fransisco', 0, 13, 'GPE')]\n",
            "('San', 3, 'GPE')\n",
            "('fransisco', 1, 'GPE')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting entity annotations\n",
        "from spacy.tokens import Span\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"fb is hiring a new VP of global policy\")\n",
        "ents=[(e.text,e.start_char,e.end_char,e.label_) for e in doc.ents]\n",
        "print(\"Before\",ents)\n",
        "# create a span for the new entity\n",
        "fb_ent=Span(doc,0,1,label=\"ORG\")\n",
        "orig_ents=list(doc.ents)\n",
        "# Modify provider entity span\n",
        "doc.set_ents([fb_ent], default=\"unmodified\")\n",
        "#  Assign a complete list of ents to doc.ents\n",
        "doc.ents=orig_ents+[fb_ent]\n",
        "ents=[(e.text,e.start_char,e.end_char,e.label_) for e in doc.ents]\n",
        "print(\"After\",ents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sje6Zw9zHtQx",
        "outputId": "0b1dc780-fa0c-4eb4-cae1-389d88a81df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before []\n",
            "After [('fb', 0, 2, 'ORG')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting entity annotations from array\n",
        "import numpy\n",
        "from spacy.attrs import ENT_IOB,ENT_TYPE\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp.make_doc(\"London is a big city in the United Kingdom\")\n",
        "print(\"Before\",doc.ents)\n",
        "\n",
        "header=(ENT_IOB,ENT_TYPE)\n",
        "attr_array=numpy.zeros((len(doc),len(header)),dtype=\"uint64\")\n",
        "attr_array[0,0]=3\n",
        "attr_array[0,1]=doc.vocab.strings[\"GPE\"]\n",
        "doc.from_array(header,attr_array)\n",
        "print(\"After\",doc.ents)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFJleFC3V6E6",
        "outputId": "46e14951-feaf-4017-855b-5574ddb1d42b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ()\n",
            "After (London,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Built-in entity types"
      ],
      "metadata": {
        "id": "zyrgiCR1grmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing named entities\n",
        "from spacy import displacy\n",
        "text=\"When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously.\"\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(text)\n",
        "displacy.serve(doc,style=\"ent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "u_EEgNtXf3rI",
        "outputId": "95f32805-b74d-4d05-f82b-0756c8c5ba61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/displacy/__init__.py:106: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
            "  warnings.warn(Warnings.W011)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
              "<html lang=\"en\">\n",
              "    <head>\n",
              "        <title>displaCy</title>\n",
              "    </head>\n",
              "\n",
              "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
              "<figure style=\"margin-bottom: 6rem\">\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sebastian Thrun\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " started working on self-driving cars at \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Google\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2007\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", few people outside of the company took him seriously.</div>\n",
              "</figure>\n",
              "</body>\n",
              "</html></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using the 'ent' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenization"
      ],
      "metadata": {
        "id": "3NzYl_bZr1r8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "for token in doc:\n",
        "  print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODtJyuPercDl",
        "outputId": "9ad5b216-c8dd-456e-a0ed-53d18808431c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple\n",
            "is\n",
            "looking\n",
            "at\n",
            "buying\n",
            "U.K.\n",
            "startup\n",
            "for\n",
            "$\n",
            "1\n",
            "billion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding special case tokenization rules\n",
        "from spacy.symbols import ORTH\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"gimme that\")\n",
        "print([w.text for w in doc])\n",
        "# Add special case rule\n",
        "special_case=[{ORTH:\"gim\"},{ORTH:\"me\"}]\n",
        "nlp.tokenizer.add_special_case(\"gimme\",special_case)\n",
        "doc=nlp(\"gimme that\")\n",
        "print([w.text for w in nlp(\"gimme that\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNNzo8AdsHCy",
        "outputId": "8fe56b68-25a5-45e3-8f6d-3ba5b5bf38b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['gimme', 'that']\n",
            "['gim', 'me', 'that']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# debugging the tokenizer\n",
        "from spacy.lang.en import English\n",
        "nlp=English()\n",
        "text='''\"Let's go!\"'''\n",
        "doc=nlp(text)\n",
        "token_exp=nlp.tokenizer.explain(text)\n",
        "for t in token_exp:\n",
        "  print(t[1],\"\\t\",t[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn-MVUXnyEOG",
        "outputId": "2931bdb0-1212-4fa0-97fc-f5bdb5e78a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\" \t PREFIX\n",
            "Let \t SPECIAL-1\n",
            "'s \t SPECIAL-2\n",
            "go \t TOKEN\n",
            "! \t SUFFIX\n",
            "\" \t SUFFIX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Customizing spaCy’s Tokenizer class\n",
        "\n",
        "import re\n",
        "from spacy.tokenizer import Tokenizer\n",
        "\n",
        "special_cases={\":)\":[{ORTH:\":)\"}]}\n",
        "prefix_re=re.compile(r'''^[\\\\[\\\\(\"']''')\n",
        "suffix_re = re.compile(r'''[\\]\\)\"']$''')\n",
        "infix_re=re.compile(r'''[-~]''')\n",
        "simple_url_re=re.compile(r'''^https?://''')\n",
        "def custom_tokenizer(nlp):\n",
        "  return Tokenizer(nlp.vocab,rules=special_cases,prefix_search=prefix_re.search,suffix_search=suffix_re.search,infix_finditer=infix_re.finditer,url_match=simple_url_re.match)\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "nlp.tokenizer=custom_tokenizer(nlp)\n",
        "doc=nlp(\"hello-word.:)\")\n",
        "print([t.text for t in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HLD7yVVD2Tx",
        "outputId": "540c9f11-7ec9-4a81-97be-b836ec1a979a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', '-', 'word.:', ')']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from spacy.lang.char_classes import ALPHA,ALPHA_LOWER,ALPHA_UPPER\n",
        "from spacy.lang.char_classes import CONCAT_QUOTES,LIST_ELLIPSES,LIST_ICONS\n",
        "from spacy.util import compile_infix_regex\n",
        "\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"Mother-in-law\")\n",
        "print([t.text for t in doc])\n",
        "\n",
        "# Modify tokenizer\n",
        "infixes=(LIST_ELLIPSES+LIST_ICONS+\n",
        "         [\n",
        "             r\"(?<=[0-9])[+\\\\-\\\\*^](?=[0-9-])\",\n",
        "             r\"(?<=[{al}{q}])\\\\.(?=[{au}{q}])\".format(\n",
        "                 al=ALPHA_LOWER,au=ALPHA_UPPER,q=CONCAT_QUOTES\n",
        "             ),\n",
        "             r\"(?<=[{a}]),(?=[{a}])\".format(a=ALPHA),\n",
        "             r\"(?<=[{a}0-9])[:<>/](?=[{a}])\".format(a=ALPHA)\n",
        "         ])\n",
        "infixes_re=compile_infix_regex(infixes)\n",
        "nlp.tokenizer.infix_finditer=infixes_re.finditer\n",
        "doc=nlp(\"Mother-in-law\")\n",
        "print([t.text for t in doc])\n"
      ],
      "metadata": {
        "id": "HUtnEMUukDs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc906c42-ec3e-4e20-9759-c51cc934f296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Mother', '-', 'in', '-', 'law']\n",
            "['Mother-in-law']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Basic whitespace tokenizer\n"
      ],
      "metadata": {
        "id": "OHt_tJT1gkgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from string import whitespace\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "class whitespacetokenizer:\n",
        "  def __init__(self,vocab):\n",
        "    self.vocab=vocab\n",
        "  def __call__(self,text):\n",
        "    words=text.split(\" \")\n",
        "    spaces=[True]*len(words)\n",
        "    for i, word in enumerate(words):\n",
        "      if word == \"\":\n",
        "        words[i]=\" \"\n",
        "        spaces[i]=False\n",
        "    if words[-1]==\"\":\n",
        "      words=words[:-1]\n",
        "      spaces=spaces[:-1]\n",
        "    else:\n",
        "      spaces[-1]=False\n",
        "    return Doc(self.vocab,words=words, spaces=spaces)\n",
        "nlp=spacy.blank(\"en\")\n",
        "nlp.tokenizer=whitespacetokenizer(nlp.vocab)\n",
        "doc=nlp(\"What's happend to me ? he thought.It wasn't a dream.\")\n",
        "print([token.text for token in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Sv1fvtPmSPx",
        "outputId": "5687c2c9-bcc7-4354-f3cf-2704afc51c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"What's\", 'happend', 'to', 'me', '?', 'he', 'thought.It', \"wasn't\", 'a', 'dream.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dctf9gmdjevI",
        "outputId": "b42e93fa-f48e-4762-bdf5-dec389b7ccbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#using Third-party tokenizers BERT word pieces"
      ],
      "metadata": {
        "id": "mqQgwurZgwNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import BertWordPieceTokenizer\n",
        "from spacy.tokens import Doc\n",
        "import spacy\n",
        "\n",
        "class BertTokenizer:\n",
        "  def __init__(self,vocab,vocab_file,lowercase=True):\n",
        "    self.vocab=vocab\n",
        "    self.tokenizer=BertWordPieceTokenizer(vocab_file,lowercase=lowercase)\n",
        "  def __call__(self,text):\n",
        "    tokens=self.tokenizer.encode(text)\n",
        "    word=[]\n",
        "    space=[]\n",
        "    for i,(text,(start,end)) in enumerate(zip(tokens.tokens,tokens.offsets)):\n",
        "      word.append(text)\n",
        "      if i < len(tokens.tokens)-1:\n",
        "        next_start,next_end=tokens.offsets[i+1]\n",
        "        space.append(next_start==start)\n",
        "      else:\n",
        "        space.append(False)\n",
        "    return Doc(self.vocab,words=word,spaces=space)\n",
        "nlp=spacy.blank(\"en\")\n",
        "nlp.tokenizer=BertTokenizer(nlp.vocab,\"bert-base-uncased-vocab.txt\")\n",
        "doc=nlp(\"Justin Dew Biber is a Canadian singer,songwriter, and actor.\")\n",
        "print([token.text for token in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ip7WeHjzH7-",
        "outputId": "e1640bf1-4dcd-4e66-930e-76c41feacd81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'justin', 'dew', 'bi', '##ber', 'is', 'a', 'canadian', 'singer', ',', 'songwriter', ',', 'and', 'actor', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using pre_tokenized text\n",
        "\n",
        "from spacy.tokens import Doc\n",
        "nlp=spacy.blank(\"en\")\n",
        "words=[\"Hello\",\",\",\"World\",\"!\"]\n",
        "spaces=[False,True,False,False]\n",
        "doc=Doc(nlp.vocab,words=words,spaces=spaces)\n",
        "print(doc.text)\n",
        "print([(t.text,t.text_with_ws,t.whitespace_ )for t in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwlpYcuBi9OK",
        "outputId": "71b50c51-5667-44bc-f8cd-8bc0846c23cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, World!\n",
            "[('Hello', 'Hello', ''), (',', ', ', ' '), ('World', 'World', ''), ('!', '!', '')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alligning tokenization\n",
        "\n",
        "from spacy.training import Alignment\n",
        "other_tokens=[\"i\",\"listeended\",\"to\", \"obama\", \"'\", \"s\", \"podcasts\", \".\"]\n",
        "spacy_tokens=[\"i\",\"listeended\",\"to\", \"obama\", \"'\", \"s\", \"podcasts\", \".\"]\n",
        "align=Alignment.from_strings(other_tokens,spacy_tokens)\n",
        "print(f\"a->b,lengths:{align.x2y.lengths}\")\n",
        "print(f\"a->b,mapping:{align.x2y.data}\")\n",
        "print(f\"a->b,lengths:{align.y2x.lengths}\")\n",
        "print(f\"a->b,mapping:{align.y2x.data}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z8nC9C-pRO-",
        "outputId": "276bc2ac-9b06-4f24-e491-7305bf915dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a->b,lengths:[1 1 1 1 1 1 1 1]\n",
            "a->b,mapping:[0 1 2 3 4 5 6 7]\n",
            "a->b,lengths:[1 1 1 1 1 1 1 1]\n",
            "a->b,mapping:[0 1 2 3 4 5 6 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Merging and splitting"
      ],
      "metadata": {
        "id": "GPbk4yKMw5eK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"I live in New York\")\n",
        "print(\"Before\",[token.text for token in doc])\n",
        "with doc.retokenize() as retokenizer:\n",
        "  retokenizer.merge(doc[3:5],attrs={\"LEMMA\":\"newyork\"})\n",
        "print(\"After\",[token.text for token in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfDqzxtvw5Eu",
        "outputId": "663c3e61-6031-4acb-acf5-c161be9554d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ['I', 'live', 'in', 'New', 'York']\n",
            "After ['I', 'live', 'in', 'New York']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Splitting tokens"
      ],
      "metadata": {
        "id": "GZHaURP2yRQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"I live in NewYork\")\n",
        "print(\"Before:\", [token.text for token in doc])\n",
        "displacy.render(doc)\n",
        "with doc.retokenize() as retokenizer:\n",
        "    heads = [(doc[3], 1), doc[2]]\n",
        "    attrs = {\"POS\": [\"PROPN\", \"PROPN\"], \"DEP\": [\"pobj\", \"compound\"]}\n",
        "    retokenizer.split(doc[3], [\"New\", \"York\"], heads=heads, attrs=attrs)\n",
        "print(\"After:\", [token.text for token in doc])\n",
        "displacy.render(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "H_xlhiDyyDFZ",
        "outputId": "4bdcb973-e8b1-4735-e480-49043d28b273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: ['I', 'live', 'in', 'NewYork']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"8c68e5b4a65547838bfb7f33513d41f4-0\" class=\"displacy\" width=\"750\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">live</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">NewYork</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8c68e5b4a65547838bfb7f33513d41f4-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8c68e5b4a65547838bfb7f33513d41f4-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8c68e5b4a65547838bfb7f33513d41f4-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8c68e5b4a65547838bfb7f33513d41f4-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M400.0,91.5 L408.0,79.5 392.0,79.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8c68e5b4a65547838bfb7f33513d41f4-0-2\" stroke-width=\"2px\" d=\"M420,89.5 C420,2.0 575.0,2.0 575.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8c68e5b4a65547838bfb7f33513d41f4-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M575.0,91.5 L583.0,79.5 567.0,79.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After: ['I', 'live', 'in', 'New', 'York']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"624416430e8946be819d4fca1b37faa5-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">live</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">New</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">York</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-624416430e8946be819d4fca1b37faa5-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-624416430e8946be819d4fca1b37faa5-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-624416430e8946be819d4fca1b37faa5-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-624416430e8946be819d4fca1b37faa5-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-624416430e8946be819d4fca1b37faa5-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-624416430e8946be819d4fca1b37faa5-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-624416430e8946be819d4fca1b37faa5-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-624416430e8946be819d4fca1b37faa5-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentence Segmentation"
      ],
      "metadata": {
        "id": "jeNJYd9wv10r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"This is a sentence.This is another sentence.\")\n",
        "assert doc.has_annotation(\"SENT_START\")\n",
        "for sent in doc.sents:\n",
        "  print(sent.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiYtYz7hyoCU",
        "outputId": "38f5ec68-4aa4-49da-e3dd-16736dfe9a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a sentence.\n",
            "This is another sentence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentence Segmentation using dependancy parse"
      ],
      "metadata": {
        "id": "aDeMq5EC2pQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"This is a sentence.This is another sentence.\")\n",
        "for sent in doc.sents:\n",
        "  print(sent.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8n4xFlVwLWg",
        "outputId": "f60d935b-9934-48af-f80d-fd3e46d2cbe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a sentence.\n",
            "This is another sentence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentence Segmentation using Statistical sentence segmenter\n"
      ],
      "metadata": {
        "id": "WTVCQu1w3G19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "nlp.enable_pipe(\"senter\")\n",
        "doc=nlp(\"This is a sentence.This is another sentence.\")\n",
        "for sent in doc.sents:\n",
        "  print(sent.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0E-sXXi2m6I",
        "outputId": "af2fca93-b152-436f-cdbb-c706f4206fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a sentence.\n",
            "This is another sentence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentence Segmentation using Rule based pipeline component"
      ],
      "metadata": {
        "id": "szCprqw44xuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English\n",
        "nlp=English()\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "doc=nlp(\"This is a sentence.This is another sentence.\")\n",
        "for sent in doc.sents:\n",
        "  print(sent.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JVBydk53i25",
        "outputId": "6f612160-d38a-4e95-b617-3ee7f0623f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a sentence.\n",
            "This is another sentence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentence Segmentation using custom rule-based strategy"
      ],
      "metadata": {
        "id": "7lPzKLK55e28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.language import Language\n",
        "text= \"this is a sentence...hello...and another sentence.\"\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(text)\n",
        "print(\"Before:\",[sent.text for sent in doc.sents])\n",
        "\n",
        "@Language.component(\"set_custom_boundaries\")\n",
        "def set_custom_boundaries(doc):\n",
        "  for token in doc[:-1]:\n",
        "    if token.text == \"...\":\n",
        "      doc[token.i+1].is_sent_start=True\n",
        "  return doc\n",
        "\n",
        "nlp.add_pipe(\"set_custom_boundaries\",before=\"parser\")\n",
        "doc=nlp(text)\n",
        "print(\"After:\",[sent.text for sent in doc.sents])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYMgcI9R5IBy",
        "outputId": "8a020826-a3f1-4fd6-bb38-4b9070f28d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: ['this is a sentence...hello...and another sentence.']\n",
            "After: ['this is a sentence...', 'hello...', 'and another sentence.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#mappings & exceptions"
      ],
      "metadata": {
        "id": "F97Xzr-ajmdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "text=\"I saw The Who perform. Who did you see?\"\n",
        "doc1=nlp(text)\n",
        "print(doc1[2].tag_,doc1[2].pos_)\n",
        "print(doc1[3].tag_,doc1[3].pos_)\n",
        "\n",
        "# add attribute ruler with exception\n",
        "ruler=nlp.get_pipe(\"attribute_ruler\")\n",
        "# pattern to match (The Who)\n",
        "patterns=[[{\"LOWER\":\"the\"},{\"TEXT\":\"Who\"}]]\n",
        "# attributes to assign to the matched token\n",
        "attrs={\"TAG\":\"NNP\",\"POS\":\"PROPN\"}\n",
        "# add rules to the attribute ruler\n",
        "ruler.add(patterns=patterns,attrs=attrs,index=0)\n",
        "ruler.add(patterns=patterns,attrs=attrs,index=1)\n",
        "\n",
        "doc2=nlp(text)\n",
        "print(doc2[2].tag_,doc2[2].pos_)\n",
        "print(doc2[3].tag_,doc2[3].pos_)\n",
        "# the second who remains unmodified\n",
        "print(doc2[5].tag_,doc2[5].pos_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9Fw47MQjd1J",
        "outputId": "1548e2f4-820a-4353-be3a-12731c1704d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DT DET\n",
            "WP PRON\n",
            "NNP PROPN\n",
            "NNP PROPN\n",
            ". PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Word vectors and semantic similarity"
      ],
      "metadata": {
        "id": "tAPb8jHfuD2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "tokens = nlp(\"dog cat banana afskfsd\")\n",
        "for token in tokens:\n",
        "    print(f\"text: {token.text}, has vector{token.has_vector}, Vector norm: {token.vector_norm}, Out of vocabulary (OOV): {token.is_oov}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsAndkQdmyXE",
        "outputId": "8cd8f62d-192c-4cf9-a77e-724294050c37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text: dog, has vectorTrue, Vector norm: 6.814785957336426, Out of vocabulary (OOV): True\n",
            "text: cat, has vectorTrue, Vector norm: 7.370901584625244, Out of vocabulary (OOV): True\n",
            "text: banana, has vectorTrue, Vector norm: 7.646069526672363, Out of vocabulary (OOV): True\n",
            "text: afskfsd, has vectorTrue, Vector norm: 7.192255973815918, Out of vocabulary (OOV): True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc1=nlp(\"I like salty fries and hamburgers\")\n",
        "doc2=nlp(\"Fast food tastes very good\")\n",
        "# similarity of both doc1 and doc2\n",
        "print(doc1,\"<->\",doc2,doc1.similarity(doc2))\n",
        "\n",
        "# similarity of tokens and span\n",
        "french_fries=doc1[2:4]\n",
        "burgers=doc1[5]\n",
        "print(french_fries,\"<->\",burgers,french_fries.similarity(burgers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWGbBBGH0Xxz",
        "outputId": "df121466-57c1-4bcd-b00c-d848d419ce2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I like salty fries and hamburgers <-> Fast food tastes very good 0.2457051288099938\n",
            "salty fries <-> hamburgers 0.3522574305534363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-4bc4a7e7d9ef>:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  print(doc1,\"<->\",doc2,doc1.similarity(doc2))\n",
            "<ipython-input-45-4bc4a7e7d9ef>:10: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Span.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  print(french_fries,\"<->\",burgers,french_fries.similarity(burgers))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating a custom language subclass"
      ],
      "metadata": {
        "id": "AOVDo5cVEghl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English\n",
        "class CustomEnglish(English.Defaults):\n",
        "  stop_words=set([\"custom\",\"stop\"])\n",
        "class CustomEnglish(English):\n",
        "  lang=\"custom_en\"\n",
        "  Defaults=CustomEnglish\n",
        "nlp1=English()\n",
        "nlp2=CustomEnglish()\n",
        "print(nlp1.lang,[token.is_stop for token in nlp1(\"custom stop\")])\n",
        "print(nlp2.lang,[token.is_stop for token in nlp2(\"custom stop\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3rGiatBC5dm",
        "outputId": "add65e0a-a421-4699-fa6b-18a27b298743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en [False, False]\n",
            "custom_en [True, True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rule-based matching"
      ],
      "metadata": {
        "id": "nYSpf1cNBf2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Token-based matching"
      ],
      "metadata": {
        "id": "CfRRW0L9FYeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import Matcher\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "matcher=Matcher(nlp.vocab)\n",
        "# Define the pattern\n",
        "pattern=[{\"LOWER\":\"hello\"},{\"IS_PUNCT\":True},{\"LOWER\":\"world\"}]\n",
        "# Add pattern to the matcher\n",
        "matcher.add(\"HelloWorld\",[pattern])\n",
        "doc=nlp(\"Hello, world! Hello world!\")\n",
        "matches=matcher(doc)\n",
        "for match_id,start,end, in matches:\n",
        "  string_id=nlp.vocab.strings[match_id]\n",
        "  span=doc[start:end]\n",
        "  print(match_id,string_id,start,end,span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1acPmgZ8eFX",
        "outputId": "9a33d6f9-3f99-4ae6-e617-78f51c96cf36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15578876784678163569 HelloWorld 0 3 Hello, world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Matching regular expressions on the full text"
      ],
      "metadata": {
        "id": "A8Wx_EmlaiJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"The United States of America (USA) are commonly known as the United States (U.S. or US) or America.\")\n",
        "expression=r\"[Uu](nited|\\.?) ?[Ss](tates|\\.?)\"\n",
        "for match in re.finditer(expression,doc.text):\n",
        "  start,end=match.span()\n",
        "  span=doc.char_span(start,end)\n",
        "  if span is not None:\n",
        "    print(\"Found match:\",span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGQkKmJk8ioF",
        "outputId": "a9d78fb9-2a0e-4de8-cbb1-9d5073f8cbb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found match: United States\n",
            "Found match: United States\n",
            "Found match: U.S.\n",
            "Found match: US\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding on_match rules"
      ],
      "metadata": {
        "id": "YOY4dWD-xmNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English\n",
        "from spacy.matcher import Matcher\n",
        "from spacy.tokens import Span\n",
        "nlp=English()\n",
        "matcher=Matcher(nlp.vocab)\n",
        "def add_event_ent(matcher,doc,i,matches):\n",
        "  match_id,start,end=matches[i]\n",
        "  entity=Span(doc,start,end,label=\"EVENT\")\n",
        "  doc.ents+=(entity,)\n",
        "  print( entity.text)\n",
        "pattern=[{\"ORTH\":\"Google\"},{\"ORTH\":\"I\"},{\"ORTH\":\"/\"},{\"ORTH\":\"O\"}]\n",
        "matcher.add(\"GoogleIO\",[pattern],on_match=add_event_ent)\n",
        "doc=nlp(\"This is a text about Google I/O\")\n",
        "matches=matcher(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WStgYxU0YyM_",
        "outputId": "a18e459b-7894-453d-fb14-b8d1e2689b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google I/O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating spans from matches"
      ],
      "metadata": {
        "id": "Q226D0zU2G1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import Matcher\n",
        "from spacy.tokens import Span\n",
        "nlp=spacy.blank(\"en\")\n",
        "matcher=Matcher(nlp.vocab)\n",
        "matcher.add(\"person\",[[{\"lower\":\"barak\"},{\"lower\":\"obama\"}]])\n",
        "doc=nlp(\"Barak Obama was the president of United States\")\n",
        "matches=matcher(doc)\n",
        "for match_id,start,end in matches:\n",
        "  span=Span(doc,start,end,label=match_id)\n",
        "  print(span.text,span.label_)\n",
        "matches=matcher(doc,as_spans=True)\n",
        "for span in matches:\n",
        "  print(span.text,span.label_)"
      ],
      "metadata": {
        "id": "G-puhD8Hyaq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d5f59d0-ed76-4e91-9ccd-f71b97151b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Barak Obama person\n",
            "Barak Obama person\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#using custom pipeline components"
      ],
      "metadata": {
        "id": "n02ygC2I-BHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.language import Language\n",
        "from spacy.matcher import Matcher\n",
        "from spacy.tokens import Token\n",
        "@Language.factory(\"html_merger\")\n",
        "def create_bad_html_merger(nlp, name):\n",
        "    return BadHTMLMerger(nlp.vocab)\n",
        "class BadHTMLMerger:\n",
        "    def __init__(self, vocab):\n",
        "        patterns = [\n",
        "            [{\"ORTH\": \"<\"}, {\"LOWER\": \"br\"}, {\"ORTH\": \">\"}],\n",
        "            [{\"ORTH\": \"<\"}, {\"LOWER\": \"br/\"}, {\"ORTH\": \">\"}],\n",
        "        ]\n",
        "        Token.set_extension(\"bad_html\", default=False)\n",
        "        self.matcher = Matcher(vocab)\n",
        "        self.matcher.add(\"BAD_HTML\", patterns)\n",
        "    def __call__(self, doc):\n",
        "        matches = self.matcher(doc)\n",
        "        spans = []\n",
        "        for match_id, start, end in matches:\n",
        "            spans.append(doc[start:end])\n",
        "        with doc.retokenize() as retokenizer:\n",
        "            for span in spans:\n",
        "                retokenizer.merge(span)\n",
        "                for token in span:\n",
        "                    token._.bad_html = True\n",
        "        return doc\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.add_pipe(\"html_merger\", last=True)\n",
        "doc = nlp(\"Hello<br>world! <br/> This is a test.\")\n",
        "for token in doc:\n",
        "    print(token.text, token._.bad_html)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp8frPS5ByW1",
        "outputId": "718ca3f9-1544-4b4d-cfda-f37fc1ffdf96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello False\n",
            "<br> True\n",
            "world False\n",
            "! False\n",
            "<br/> True\n",
            "This False\n",
            "is False\n",
            "a False\n",
            "test False\n",
            ". False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#using linguistic annotation"
      ],
      "metadata": {
        "id": "A93fGMaXHRm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "from spacy.matcher import Matcher\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "matcher=Matcher(nlp.vocab)\n",
        "matcher_sents=[]\n",
        "def collect_sents(matcher,doc,i,matches):\n",
        "  match_id,start,end=matches[i]\n",
        "  span=doc[start:end]\n",
        "  sent=span.sent\n",
        "  match_ents=[{\"start\":span.start_char-sent.start_char,\n",
        "               \"end\":span.end_char-sent.start_char,\n",
        "               \"label\":\"MATCH\",}]\n",
        "  matcher_sents.append(({\"text\":sent.text,\"ents\":match_ents}))\n",
        "pattern = [{\"LOWER\": \"facebook\"}, {\"LEMMA\": \"be\"}, {\"POS\": \"ADV\", \"OP\": \"*\"},\n",
        "           {\"POS\": \"ADJ\"}]\n",
        "matcher.add(\"FacebookIs\",[pattern],on_match=collect_sents)\n",
        "doc=nlp(\"I'd say that Facebook is evil. - Facebook is pretty cool, right?\")\n",
        "matches=matcher(doc)\n",
        "displacy.render(matcher_sents,style=\"ent\",manual=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "kU7H2GdYCv-S",
        "outputId": "5a890346-31db-484f-8103-e0041c2a0cb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I'd say that \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Facebook is evil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MATCH</span>\n",
              "</mark>\n",
              ".</div>\n",
              "\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">- \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Facebook is pretty cool\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MATCH</span>\n",
              "</mark>\n",
              ", right?</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detect phone numbers in a specific format"
      ],
      "metadata": {
        "id": "gSyP9M4uecmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "matcher=Matcher(nlp.vocab)\n",
        "pattern=[{\"ORTH\": \"(\"}, {\"SHAPE\": \"ddd\"}, {\"ORTH\": \")\"}, {\"SHAPE\": \"ddd\"},\n",
        "           {\"ORTH\": \"-\", \"OP\": \"?\"}, {\"SHAPE\": \"ddd\"}]\n",
        "matcher.add(\"PHONE_NUMBER\",[pattern])\n",
        "doc=nlp(\"Call me at (123) 456 789 or (123) 456-789!\")\n",
        "print([t.text for t in doc])\n",
        "matches=matcher(doc)\n",
        "for match_id,start,end in matches:\n",
        "  span=doc[start:end]\n",
        "  print(span.text)"
      ],
      "metadata": {
        "id": "lsr18JyeKx9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fce7d61-19d6-4929-d1c7-649bb8134dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Call', 'me', 'at', '(', '123', ')', '456', '789', 'or', '(', '123', ')', '456', '-', '789', '!']\n",
            "(123) 456 789\n",
            "(123) 456-789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hashtags and emoji on social media"
      ],
      "metadata": {
        "id": "Clmn3y4TlkN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English\n",
        "from spacy.matcher import Matcher\n",
        "nlp=English()\n",
        "matcher=Matcher(nlp.vocab)\n",
        "pos_emoji=[\"😀\",\"😃\",\"😂\",\"🤣\",\"😊\",\"😍\"]\n",
        "neg_emoji=[\"😞\",\"😠\",\"😩\",\"😢\",\"😭\",\"😒\"]\n",
        "pos_patterns=[[{\"ORTH\":emoji}] for emoji in pos_emoji]\n",
        "neg_patterns=[[{\"ORTH\":emoji}] for emoji in neg_emoji]\n",
        "\n",
        "def lable_sentiment(matcher,doc,i,matches):\n",
        "  match_id,start,end=matches[i]\n",
        "  if doc.vocab.strings[match_id]==\"HAPPY\":\n",
        "    doc.sentiment+=0.1\n",
        "  elif doc.vocab.strings[match_id]==\"SAD\":\n",
        "    doc.sentiment-=0.1\n",
        "matcher.add(\"HAPPY\",pos_patterns,on_match=lable_sentiment)\n",
        "matcher.add(\"SAD\",neg_patterns,on_match=lable_sentiment)\n",
        "matcher.add(\"HASHTAG\",[[{\"ORTH\":\"#\"},{\"IS_ASCII\":True}]])\n",
        "doc=nlp(\"Hello world 😀 #MondayMotivation\")\n",
        "matches=matcher(doc)\n",
        "for match_id,start,end in matches:\n",
        "  string_id=doc.vocab.strings[match_id]\n",
        "  span=doc[start:end]\n",
        "  print(string_id,span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5Seue6ig4Al",
        "outputId": "d9c39630-7949-42fb-ce21-47d1ca3365b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HAPPY 😀\n",
            "HASHTAG #MondayMotivation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Phrase Matcher"
      ],
      "metadata": {
        "id": "OrPjqck-6yRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Efficient phrase matching"
      ],
      "metadata": {
        "id": "QB1AC4YQ6nAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import PhraseMatcher\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = PhraseMatcher(nlp.vocab)\n",
        "terms = [\"Barack Obama\", \"Angela Merkel\", \"Washington, D.C.\"]\n",
        "patterns = [nlp.make_doc(text) for text in terms]\n",
        "matcher.add(\"TerminologyList\", patterns)\n",
        "doc = nlp(\"German Chancellor Angela Merkel and US President Barack Obama \"\n",
        "          \"converse in the Oval Office inside the White House in Washington, D.C.\")\n",
        "matches = matcher(doc)\n",
        "for match_id, start, end in matches:\n",
        "    span = doc[start:end]\n",
        "    print(span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsHQc4OdxFWO",
        "outputId": "fafb6a38-0fc7-41c8-9449-29dc6c645b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Angela Merkel\n",
            "Barack Obama\n",
            "Washington, D.C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependency Matcher\n"
      ],
      "metadata": {
        "id": "WczY1MNtsdo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import DependencyMatcher\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "matcher=DependencyMatcher(nlp.vocab)\n",
        "pattern=[\n",
        "  {\n",
        "    \"RIGHT_ID\": \"anchor_founded\",\n",
        "    \"RIGHT_ATTRS\": {\"ORTH\": \"founded\"}\n",
        "  }\n",
        "]\n",
        "matcher.add(\"FOUNDED\",[pattern])\n",
        "doc=nlp(\"Smith founded two companies.\")\n",
        "matches=matcher(doc)\n",
        "print(matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ3ZykESb_mS",
        "outputId": "8dda3bdb-858a-4306-cc2c-d9a8701bab71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(4851363122962674176, [1])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import DependencyMatcher\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "matcher=DependencyMatcher(nlp.vocab)\n",
        "pattern = [\n",
        "    {\n",
        "        \"RIGHT_ID\": \"anchor_founded\",\n",
        "        \"RIGHT_ATTRS\": {\"ORTH\": \"founded\"}\n",
        "    },\n",
        "    {\n",
        "        \"LEFT_ID\": \"anchor_founded\",\n",
        "        \"REL_OP\": \">\",\n",
        "        \"RIGHT_ID\": \"founded_subject\",\n",
        "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"},\n",
        "    },\n",
        "    {\n",
        "        \"LEFT_ID\": \"anchor_founded\",\n",
        "        \"REL_OP\": \">\",\n",
        "        \"RIGHT_ID\": \"founded_object\",\n",
        "        \"RIGHT_ATTRS\": {\"DEP\": \"dobj\"},\n",
        "    },\n",
        "    {\n",
        "        \"LEFT_ID\": \"founded_object\",\n",
        "        \"REL_OP\": \">\",\n",
        "        \"RIGHT_ID\": \"founded_object_modifier\",\n",
        "        \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"amod\", \"compound\"]}},\n",
        "    }\n",
        "]\n",
        "matcher.add(\"FOUNDED\",[pattern])\n",
        "doc=nlp(\"Lee, an experienced CEO, has founded two AI startups.\")\n",
        "matches=matcher(doc)\n",
        "print(matches)\n",
        "match_id,token_ids=matches[0]\n",
        "for i in range(len(token_ids)):\n",
        "  print(pattern[i][\"RIGHT_ID\"]+\":\",doc[token_ids[i]].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9IEigjFtek4",
        "outputId": "93e137b8-7fe4-4ee5-a670-e2bb67718b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(4851363122962674176, [7, 0, 10, 9])]\n",
            "anchor_founded: founded\n",
            "founded_subject: Lee\n",
            "founded_object: startups\n",
            "founded_object_modifier: AI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Entity Ruler"
      ],
      "metadata": {
        "id": "I7gZPCntDncr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English\n",
        "nlp=English()\n",
        "ruler=nlp.add_pipe(\"entity_ruler\")\n",
        "patterns=[{\"label\": \"ORG\", \"pattern\": \"Apple\"},{\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"francisco\"}]}]\n",
        "ruler.add_patterns(patterns)\n",
        "doc=nlp(\"Apple is opening its first big office in San Francisco.\")\n",
        "print([(ent.text,ent.label_) for ent in doc.ents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g7SBq-Szxhu",
        "outputId": "6089f7ca-b74b-4440-8d5f-021920508dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Apple', 'ORG'), ('San Francisco', 'GPE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding Ids to patterns\n",
        "from spacy.lang.en import English\n",
        "nlp=English()\n",
        "ruler=nlp.add_pipe(\"entity_ruler\")\n",
        "patterns = [{\"label\": \"ORG\", \"pattern\": \"Apple\", \"id\": \"apple\"},\n",
        "            {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"francisco\"}], \"id\": \"san-francisco\"},\n",
        "            {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"fran\"}], \"id\": \"san-francisco\"}]\n",
        "ruler.add_patterns(patterns)\n",
        "doc1=nlp(\"Apple is opening its first big office in San Francisco.\")\n",
        "print([(ent.text,ent.label_) for ent in doc1.ents])\n",
        "doc2=nlp(\"Apple is opening its first big office in San Francisco.\")\n",
        "print([(ent.text,ent.label_) for ent in doc2.ents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4hlmySsEIpc",
        "outputId": "50b63cf4-5aa5-40e4-c5a9-7b8c912cd2b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Apple', 'ORG'), ('San Francisco', 'GPE')]\n",
            "[('Apple', 'ORG'), ('San Francisco', 'GPE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Span Ruler"
      ],
      "metadata": {
        "id": "OTdl66RJ-pvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.blank(\"en\")\n",
        "ruler=nlp.add_pipe(\"span_ruler\")\n",
        "patterns = [{\"label\": \"ORG\", \"pattern\": \"Apple\"},\n",
        "            {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"francisco\"}]}]\n",
        "ruler.add_patterns(patterns)\n",
        "doc=nlp(\"Apple is opening its first big office in San Francisco.\")\n",
        "print([(span.text,span.label_) for span in doc.spans[\"ruler\"]])"
      ],
      "metadata": {
        "id": "LtXZhuxhEi57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "555a38a8-f25a-487a-a3d2-38d7ce3430be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Apple', 'ORG'), ('San Francisco', 'GPE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "config={\"spans_key\":None,\"annotate_ents\":True,\"overwrite\":False}\n",
        "ruler=nlp.add_pipe(\"span_ruler\",config=config)\n",
        "patterns = [{\"label\": \"ORG\", \"pattern\": \"MyCorp Inc.\"}]\n",
        "ruler.add_patterns(patterns)\n",
        "doc=nlp(\"MyCorp Inc. is a company in the U.S.\")\n",
        "print([(ent.text,ent.label_) for ent in doc.ents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1-QMBz9ApPU",
        "outputId": "865546d3-4d5a-4580-c5f8-7b17f2230cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('MyCorp Inc.', 'ORG'), ('U.S.', 'GPE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Combining models and rules"
      ],
      "metadata": {
        "id": "lCY5KErpIUT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expanding named entities\n",
        "from spacy.language import Language\n",
        "from spacy.tokens import Span\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "@Language.component(\"expand_person_entities\")\n",
        "def expand_person_entities(doc):\n",
        "  new_ents=[]\n",
        "  for ent in doc.ents:\n",
        "    if ent.label_==\"PERSON\" and ent.start!=0:\n",
        "      prev_token=doc[ent.start-1]\n",
        "      if prev_token.text in (\"Dr\",\"Dr.\",\"Mr\",\"Mr.\",\"Ms\",\"Ms.\"):\n",
        "        new_ent=Span(doc,ent.start-1,ent.end,label=ent.label)\n",
        "        new_ents.append(new_ent)\n",
        "      else:\n",
        "        new_ents.append(ent)\n",
        "    else:\n",
        "      new_ents.append(ent)\n",
        "  doc.ents=new_ents\n",
        "  return doc\n",
        "nlp.add_pipe(\"expand_person_entities\",after=\"ner\")\n",
        "doc=nlp(\"Dr. Alex Smith chaired first board meeting of Acme Corp Inc.\")\n",
        "print([(ent.text,ent.label_) for ent in doc.ents])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ3iMpXXDlsf",
        "outputId": "4ecc9901-9a24-477c-bd90-a5638fcb840c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Dr. Alex Smith', 'PERSON'), ('first', 'ORDINAL'), ('Acme Corp Inc.', 'ORG')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.tokens import span\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "def get_person_title(span):\n",
        "  if span.label_==\"PERSON\"and span.start!=0:\n",
        "    prev_token=span.doc[span.start-1]\n",
        "    if prev_token.text in (\"Dr\",\"Dr.\",\"Mr\",\"Mr.\",\"Ms\",\"Ms.\"):\n",
        "      return prev_token.text\n",
        "Span.set_extension(\"person_title\",getter=get_person_title)\n",
        "doc=nlp(\"Dr. Alex Smith chaired first board meeting of Acme Corp Inc.\")\n",
        "print([(ent.text,ent.label_,ent._.person_title) for ent in doc.ents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H54Ikr8I1Qp",
        "outputId": "2fe246d5-05ee-4513-cc06-9ecfe27757c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Alex Smith', 'PERSON', 'Dr.'), ('first', 'ORDINAL', None), ('Acme Corp Inc.', 'ORG', None)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using entities, part-of-speech tags and the dependency parse"
      ],
      "metadata": {
        "id": "s7HPxkeXiomd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.language import Language\n",
        "from spacy import displacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "@Language.component(\"extract_person_orgs\")\n",
        "def extract_person_orgs(doc):\n",
        "  person_entities=[ent for ent in doc.ents if ent.label_==\"PERSON\"]\n",
        "  for ent in person_entities:\n",
        "    head=ent.root.head\n",
        "    if head.lemma_==\"work\":\n",
        "      preps=[token for token in head.children if token.dep_==\"prep\"]\n",
        "      for prep in preps:\n",
        "        orgs=[token for token in prep.children if token.ent_type_==\"ORG\"]\n",
        "        print({'person': ent, 'orgs': orgs, 'past': head.tag_ == \"VBD\"})\n",
        "  return doc\n",
        "nlp.add_pipe(\"merge_entities\")\n",
        "nlp.add_pipe(\"extract_person_orgs\")\n",
        "doc=nlp(\"Alex Smith worked at Acme Corp Inc.\")\n",
        "displacy.render(doc,options={\"fine_grained\":True})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "rBk6VuofOqvc",
        "outputId": "cf30ff87-f4d6-4515-84c5-1b58b0b7d9a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'person': Alex Smith, 'orgs': [Acme Corp Inc.], 'past': True}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"9403157bc2b14f86af3da9d2e713e2b7-0\" class=\"displacy\" width=\"750\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Alex Smith</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NNP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">worked</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VBD</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">at</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">IN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Acme Corp Inc.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NNP</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9403157bc2b14f86af3da9d2e713e2b7-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9403157bc2b14f86af3da9d2e713e2b7-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9403157bc2b14f86af3da9d2e713e2b7-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9403157bc2b14f86af3da9d2e713e2b7-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M400.0,91.5 L408.0,79.5 392.0,79.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9403157bc2b14f86af3da9d2e713e2b7-0-2\" stroke-width=\"2px\" d=\"M420,89.5 C420,2.0 575.0,2.0 575.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9403157bc2b14f86af3da9d2e713e2b7-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M575.0,91.5 L583.0,79.5 567.0,79.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OLzQExKdkirQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}